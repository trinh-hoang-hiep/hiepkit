import matplotlib.pyplot as plt
import IPython.display as ipd
MAX_INT = 32768
import numpy as np

import os
from datetime import datetime
import json
import math
import torch
from torch import nn
from torch.nn import functional as F
from torch.utils.data import DataLoader

import commons
import utils
from data_utils import TextAudioLoader, TextAudioCollate, TextAudioSpeakerLoader, TextAudioSpeakerCollate
from models import SynthesizerTrn
from text.symbols import symbols
from text.symbols_character_shortsilence import symbols as symbolscharacter
from text import text_to_sequence

from scipy.io.wavfile import write

import argparse
import time
import re


import asyncio
from text2phonemesequence import Text2PhonemeSequence
from tests.nguyenlm_text_normalization import norm_text_extend
from normalize_input.normalize import normalize_input_text_to_speech
from utils_text import split_long_document

def get_text(text,is_character, hps):
    text_norm = text_to_sequence(text, hps.data.text_cleaners,is_character=is_character)
    if hps.data.add_blank:
        text_norm = commons.intersperse(text_norm, 0)

    text_norm = torch.LongTensor(text_norm)
    return text_norm

# Load Text2PhonemeSequence
model = Text2PhonemeSequence(pretrained_g2p_model='charsiu/g2p_multilingual_byT5_small_100', language='vie-n-fix', is_cuda=True)


def convert_text_to_phoneme(list_token):
  phones=[]
  for token in list_token:
    subphones=[]
    for subtoken in token.split("-"):
      subphones.append(model.infer_sentence(subtoken).replace(" ", "").replace("â–", " "))
    phones.append("-".join(subphones))
  return phones


def tokenize_text_for_short_silence(text):
    text=text.replace("@", "a_cÃ²ng")
    tokenized_text=norm_text_extend(text)
    return tokenized_text



def deEmojify(text):
    regrex_pattern = re.compile(pattern = "["
        u"\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           "]+", flags = re.UNICODE)
    return regrex_pattern.sub(r'',text)




def convert_rawtext_to_phoneme(text):
    
    text=deEmojify(text)
    text=tokenize_text_for_short_silence(text)
    textarr=text.split(" ")
    mask_equal=[0 if i !="=" else 1 for i in textarr]
    phonemes=convert_text_to_phoneme(textarr)
    phonemes=[ "=" if (mask ==1) else phonemes[i] for i, mask in enumerate(mask_equal)]#####["=" if mask_equal[i] ==1 else phonemes[i] for i in range(mask_equal)]
    stringphoneme=" ".join(phonemes)
    return stringphoneme

arrtext=[
#          "anh ta Ä‘Æ°Æ¡ng tráº£i qua má»™t giáº·ng Ä‘Æ°á»ng luáº©n quáº©n khÃ´ng vinh hiá»ƒn",
#          "vÃ  phá»¥c tÃ¹ng sá»‘ pháº­n Ä‘Ã£ khiáº¿n cho anh cÃ³ má»™t tÃ¢m há»“n thanh báº¡ch",
# #          "â€¢ Cáº¯t lá»›p 3 cháº¥t liá»‡u cáº§u ká»³ káº¿t há»£p cotton co giÃ£n thoáº£i mÃ¡i , dá»‡t thoÃ¡ng nháº¹ mÃ¡t @ ðŸŒ¬",
#          "nÃªn khi pháº£i Ä‘Ã¡nh-thá»©c nhau chÃºng Ä‘Ã¡ vÃ o máº¡ng má»¡ cá»§a nhau mÃ  la lÃªn",
#          "Ä‘á»ƒ hun Ä‘Ãºc anh ta trá»Ÿ nÃªn má»™t káº» láº©n tháº©n",
#          "chá»‰ vÃ¬ nÃ³i tá»›i cÃ¡i quáº£ng trÆ°á»ng áº¥y",
#          "nhÆ°ng mÃ  vá»‘n cÃ³ Ã³c má»™t nhÃ  triáº¿t lÃ½",
#          "phÃºc chá»‰ Ä‘Ã¡p tháº¿ nÃ o cho pháº£i phÃ©p",
        "Tuáº§n nÃ y, FPT Software AI Center gáº¥p Ä‘Ã´i niá»m vui khi 2 bÃ i bÃ¡o nghiÃªn cá»©u má»›i cá»§a cÃ¡c há»c viÃªn chÆ°Æ¡ng trÃ¬nh AI Residency Ä‘Ã£ Ä‘Æ°á»£c cháº¥p nháº­n táº¡i Há»™i nghá»‹ The Association for Computational Linguistics thÆ°á»ng niÃªn láº§n thá»© 62 (ACL 2024).",
        "Há»™i nghá»‹ The Association for Computational Linguistics (ACL) lÃ  há»™i nghá»‹ quá»‘c táº¿ hÃ ng Ä‘áº§u (rank A*) vá» lÄ©nh vá»±c ngÃ´n ngá»¯ há»c tÃ­nh toÃ¡n, bao gá»“m nhiá»u lÄ©nh vá»±c nghiÃªn cá»©u Ä‘a dáº¡ng liÃªn quan Ä‘áº¿n cÃ¡c phÆ°Æ¡ng phÃ¡p tÃ­nh toÃ¡n Ä‘á»‘i vá»›i ngÃ´n ngá»¯ tá»± nhiÃªn",
        "ÄÃ¢y lÃ  há»™i nghá»‹ thÆ°á»ng niÃªn Ä‘Æ°á»£c tá»• chá»©c bá»Ÿi Hiá»‡p há»™i NgÃ´n ngá»¯ há»c tÃ­nh toÃ¡n, thu hÃºt ráº¥t nhiá»u cÃ¡c nhÃ  nghiÃªn cá»©u, cÃ¡c tÃ i nÄƒng trong lÄ©nh vá»±c cÃ´ng nghá»‡ Ä‘áº¿n tá»« kháº¯p nÆ¡i trÃªn tháº¿ giá»›i",
        "Há»™i nghá»‹ ACL láº§n thá»© 62 sáº½ diá»…n ra táº¡i Trung tÃ¢m Há»™i nghá»‹ Centara Grand and Bangkok, Bangkok, ThÃ¡i Lan tá»« ngÃ y 11 Ä‘áº¿n ngÃ y 16 thÃ¡ng 8 nÄƒm nay",
        "CÃ¡c mÃ´ hÃ¬nh Transformer Ä‘Æ°á»£c chá»©ng minh khÃ´ng bá»n vá»¯ng vá»›i cÃ¡c vÄƒn báº£n Ä‘á»‘i nghá»‹ch. CÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ Ä‘á»™ bá»n vá»¯ng thÆ°á»ng chá»‰ Ä‘Æ°á»£c thá»±c hiá»‡n sau khi tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh mÃ  khÃ´ng quan tÃ¢m Ä‘áº¿n dá»¯ liá»‡u huáº¥n luyá»‡n. Trong bÃ i bÃ¡o nÃ y, nhÃ³m nghiÃªn cá»©u Ä‘Ã£ chá»©ng minh ráº±ng cÃ³ má»‘i tÆ°Æ¡ng quan cháº·t cháº½ giá»¯a dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  Ä‘á»™ bá»n vá»¯ng cá»§a mÃ´ hÃ¬nh. Táº­p trung chá»§ yáº¿u vÃ o cÃ¡c mÃ´ hÃ¬nh Transformer Encoder-only nhÆ° BERT vÃ  RoBERTa cÃ¹ng vá»›i cÃ¡c káº¿t quáº£ bá»• sung cho Decoder-only vÃ  Encoder-Decoder nhÆ° BART, ELECTRA vÃ  GPT2, nhÃ³m Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ chá»©ng minh luáº­n Ä‘iá»ƒm nÃ y. NgoÃ i ra, phÆ°Æ¡ng phÃ¡p nÃ y cÃ²n cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° má»™t cÃ´ng cá»¥ nhanh chÃ³ng vÃ  hiá»‡u quáº£ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ bá»n vá»¯ng cá»§a cÃ¡c mÃ´ hÃ¬nh Transformer.",
        "BÃ i bÃ¡o giá»›i thiá»‡u SRank, má»™t phÆ°Æ¡ng phÃ¡p xáº¿p háº¡ng má»›i dÃ nh cho viá»‡c lá»±a chá»n cÃ¡c giáº£i phÃ¡p code tá»‘t nháº¥t tá»« cÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n vá» Code (CodeLLMs). SRank sá»­ dá»¥ng phÃ¢n tÃ­ch má»‘i quan há»‡ vÃ  sá»± tÆ°Æ¡ng Ä‘á»“ng chá»©c nÄƒng giá»¯a cÃ¡c cá»¥m giáº£i phÃ¡p code Ä‘á»ƒ cáº£i thiá»‡n quÃ¡ trÃ¬nh xáº¿p háº¡ng. Káº¿t quáº£ nghiÃªn cá»©u cho tháº¥y SRank Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ xuáº¥t sáº¯c vá»›i Ä‘iá»ƒm pass@1 trÃªn nhiá»u tiÃªu chuáº©n, vÆ°á»£t trá»™i hÆ¡n so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n táº¡i vá»›i má»©c trung bÃ¬nh lÃ  6,1%.",
        "lÃ  tá»• chá»©c tá»“n táº¡i Ä‘áº¿n nay, cáº£i cÃ¡ch hÃ nh chÃ­nh vÃ  chá»‘ng tham nhÅ©ng",
        "Ã´ng Ä‘Æ°á»£c tá»• chá»©c cá»­ vá» nÆ°á»›c, cÃ¹ng vá»›i má»™t sá»‘ Ä‘á»“ng chÃ­ cá»§a Ã´ng, Ä‘á»ƒ tuyÃªn truyá»n tÆ° tÆ°á»Ÿng cÃ¡ch máº¡ng cho thanh niÃªn á»Ÿ thanh hÃ³a",
        "lÃ£o ká»ƒ cÃ³ hÃ´m lÃ£o Ä‘áº¿n má»™t thá»‹ tráº¥n chÆ¡i, cÃ³ lÃ£o há» lÃ½ chÆ¡i thua nhiá»u quÃ¡, nÃªn gÃ£ Ä‘em Ä‘á»“ kÃ½ gá»­i ra mÃ  cÆ°á»£c láº¥y máº¥y chiáº¿c rÆ°Æ¡ng to, khi má»Ÿ ra toÃ n vÃ ng rÃ²ng",
        "Ba chá»‹ em bÃ¢y hÃ£y dáº¥u mÃ¬nh yÃªu quÃ¡i,  trÃ  trá»™n vÃ o cung Ä‘iá»‡n,  lÃ m cho Trá»¥ vÆ°Æ¡ng Ä‘iÃªu Ä‘á»©ng, Ä‘á»£i cho vÃµ vÆ°Æ¡ng Ä‘Ã¡nh trá»¥ thÃ nh cÃ´ng, ta cho chÃºng bay thÃ nh tháº§n",
        "Náº¿u ta khÃ´ng bÃ¡o á»©ng cho háº¯n sao gá»i lÃ  linh, nÃ³i rá»“i liá»n Ä‘áº±ng vÃ¢n bay vÃ o triá»u, cá»‘ váº­t cháº¿t vua Trá»¥ Ä‘á»ƒ rá»­a há»n"
         
         ]

if __name__ == '__main__':
    for text in arrtext:
        # args
        parser = argparse.ArgumentParser()
        parser.add_argument("--config", default="/home/thhiep/mayt4/text-to-speech/logs/nam_mienbac_doctruyen/config.json")
        parser.add_argument("--model", default="/home/thhiep/mayt4/text-to-speech/logs/nam_mienbac_doctruyen/G_50000.pth")
        parser.add_argument("--text", default=text)
        parser.add_argument("--is_character", action="store_true")
        args = parser.parse_args()
        
        # load model
        hps = utils.get_hparams_from_file(args.config)
        print(args.is_character)

        # net_g = SynthesizerTrn(
        #     len(symbols),
        #     hps.data.filter_length // 2 + 1,
        #     hps.train.segment_size // hps.data.hop_length,
        #     **hps.model).to("cpu")
        # _ = net_g.eval()

        # _ = utils.load_checkpoint(args.model, net_g, None)


        if(args.is_character):##### do nothing
            lensymbols=len(symbolscharacter)
            args.text=norm_text_extend(args.text)
            print("text Ä‘Æ°a vÃ o model", args.text) ##### bá» async
        if(not args.is_character):#####store_true
            lensymbols=len(symbols)
            ###feature is disable
            args.text=convert_rawtext_to_phoneme(args.text)
            print("text Ä‘Æ°a vÃ o model", args.text)
        
        net_g = SynthesizerTrn(
            lensymbols,
            hps.data.filter_length // 2 + 1,
            hps.train.segment_size // hps.data.hop_length,
            **hps.model).to("cpu")
        _ = net_g.eval()

        _ = utils.load_checkpoint(args.model, net_g, None)
            
        
        stn_tst = get_text(args.text,args.is_character,  hps)
        with torch.no_grad():
            x_tst = stn_tst.to("cpu").unsqueeze(0)
            
            x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).to("cpu")
            start = time.time()
            audio = net_g.infer(x_tst, x_tst_lengths, noise_scale=.667, noise_scale_w=0.8, length_scale=1.1)[0][0,0].data.cpu().float().numpy()
            
            end = time.time()

        date = datetime.now().strftime("%Y-%m-%d_%I-%M-%S")
        
        # Increase volume
        audio = np.int16(audio * MAX_INT)
        mean_volume_db = 20 * np.log10(np.abs(audio).mean() / MAX_INT)
        # print(f"Mean volume before: {mean_volume_db} dB, {np.abs(audio).mean()}")

        # TÄƒng volume theo giÃ¡ trá»‹ db muá»‘n Ä‘áº¡t Ä‘Æ°á»£c
        target_volume_db = -25
        gain = 10 ** ((target_volume_db - mean_volume_db) / 20)
        # print(f"Audio gain: {gain}")
        if gain >= 1.0:
            audio_gain = audio * np.int16(gain)
            mean_volume_db = 20 * np.log10(np.abs(audio_gain).mean() / MAX_INT)
            if not mean_volume_db == -np.inf:
                print(f"Mean volume after: {mean_volume_db} dB, {np.abs(audio_gain).mean()}, {gain}")
                audio = audio_gain
            # else:
        write(f'/home/thhiep/mayt4/text-to-speech/infer_final/{date}.wav', hps.data.sampling_rate, audio)
        print(f'{date}.wav')
        import time
        time.sleep(1)
